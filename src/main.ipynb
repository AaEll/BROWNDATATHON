{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import operator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gc\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import random\n",
    "import datetime as dt\n",
    "\n",
    "def find_neighbors(data, lat,long,k,n1 = 'geocode_latitude',n2 = 'geocode_longitude'):\n",
    "    tmp_arr = data[[n1,n2]]-np.array([lat,long])\n",
    "    temp_ser = np.sum(np.square(tmp_arr),axis = 1)\n",
    "    indexes = np.argsort(temp_ser)[0:k]\n",
    "    return data.loc[indexes,:]\n",
    "\n",
    "def avg_residuals(data,model, target = 'sale_amt'):\n",
    "    return np.sum(model.predict(data.drop('sale_amt')) - data['sale_amt'])\n",
    "    \n",
    "def K_NN_Residuals(model,data,lat,long,k = 5,target = 'sale_amt',n1 = 'geocode_latitude',n2 = 'geocode_longitude'):\n",
    "    return avg_residuals(find_neighbors(data,lat,long,k,n1,n2),model,target)\n",
    "\n",
    "def model_fill(data,model,target):\n",
    "    truth_val = pd.isna(data[target])\n",
    "    test = data[truth_val]\n",
    "    train = data[~truth_val]\n",
    "    \n",
    "    model.fit(train)\n",
    "    data.loc[truth_val,:] = model.predict(test)\n",
    "    return data                 \n",
    "\n",
    "def make_one_hot_encoding(data,number_of_top_values,target):\n",
    "    top_names = list(dict(data[target].value_counts()).keys())[0:number_of_top_values]\n",
    "    for name in top_names:\n",
    "        data[name] = 0\n",
    "        data.loc[data[target] == name, name] = 1\n",
    "    data.drop(target,axis = 1, inplace = True)        \n",
    "    return data\n",
    "\n",
    "\n",
    "def make_ordinal(data,target,ordered_list):\n",
    "    dict_ordered = {}\n",
    "    i = len(ordered_list)\n",
    "    \n",
    "    name_mod = target + '_ordinal'\n",
    "    data[name_mod] = 0\n",
    "    for name in ordered_list:\n",
    "        data.loc[data[target] == name, name_mod] = i\n",
    "        i -= 1\n",
    "    data.drop(target,axis = 1, inplace = True)\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaell/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (1,3,4,9,10,11,17,19,20,34,45,46,47,48,50,51,52,53,54,55,56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Import Data\n",
    "train = pd.read_csv('../data/datathon_propattributes.csv')\n",
    "train = train[train['IsTraining'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropped_cols = ['irregular_lot_flg','prop_house_number_suffix','apn',\n",
    "                'IsTraining',\n",
    "                'fips_cd',\n",
    "                'prop_house_number',\n",
    "                'prop_house_number_2'  ,\n",
    "                'prop_house_number_suffix' ,\n",
    "                'prop_direction_left'  ,\n",
    "                'prop_street_name'  ,     \n",
    "                'prop_suffix'  ,\n",
    "                'prop_direction_right' ,\n",
    "                'prop_unit_number' ,\n",
    "                'prop_city' ,\n",
    "                'prop_state',\n",
    "                'prop_zip_code' ,\n",
    "                'prop_zip_plus_4',\n",
    "               'census_tract',\n",
    "                'mobile_home_ind',\n",
    "               'irregular_lot_flg',\n",
    "               'tax_cd_area',\n",
    "               ]\n",
    "one_hots = [['dwelling_type',27],\n",
    "            ['zoning',15],\n",
    "            ['roof_type',9],\n",
    "            ['roof_cover',13],\n",
    "            ['garage_type',14],\n",
    "            ['construction_type',13],\n",
    "            ['basement_cd',7],\n",
    "            ['style',20],\n",
    "            ['mobile_home_ind',1],\n",
    "            ['timeshare_ind',1],\n",
    "            ['distressed_sale_flg',1]]\n",
    "\n",
    "candidates_fill = ['assessed_total_value',\n",
    "                   'assessed_land_value',\n",
    "                   'assessed_improvement_value',\n",
    "                  'market_total_value',\n",
    "                  'market_land_value',\n",
    "                  'market_improvement_value',\n",
    "                  'tax_amt',\n",
    "                    'avm_final_value0',\n",
    "                    'avm_std_deviation0',\n",
    "                    'avm_final_value1',\n",
    "                    'avm_std_deviation1',\n",
    "                    'avm_final_value2'   ,            \n",
    "                    'avm_std_deviation2',\n",
    "                    'avm_final_value3'   ,            \n",
    "                    'avm_std_deviation3',\n",
    "                    'avm_final_value4',\n",
    "                    'avm_std_deviation4' ]\n",
    "\n",
    "train.drop(dropped_cols,axis =1 , inplace = True)\n",
    "\n",
    "for target_column, number_of_top_names in one_hots:\n",
    "    make_one_hot_encoding(train,number_of_top_names,target_column)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'29': 151887,\n",
       " '29.0': 3330,\n",
       " '30': 1495,\n",
       " '31': 66416,\n",
       " '31.0': 988,\n",
       " '32': 1420,\n",
       " '32.0': 48,\n",
       " '33': 10175,\n",
       " '33.0': 2042,\n",
       " '34': 6318,\n",
       " '34.0': 2296,\n",
       " '35': 43851,\n",
       " '35.0': 644,\n",
       " '36': 11601,\n",
       " '36.0': 184,\n",
       " '38': 141994,\n",
       " '38.0': 5659,\n",
       " '39': 8,\n",
       " '40': 13718,\n",
       " '40.0': 1728,\n",
       " '41': 29046,\n",
       " '41.0': 1408,\n",
       " '42': 703,\n",
       " 'A-Frame': 473,\n",
       " 'Bungalow': 23772,\n",
       " 'Cape Cod': 120489,\n",
       " 'Colonial': 244710,\n",
       " 'Contemporary': 26643,\n",
       " 'Conventional': 142698,\n",
       " 'Cottage': 6026,\n",
       " 'Custom': 4926,\n",
       " 'Dome': 12,\n",
       " 'English': 16,\n",
       " 'High-rise': 4302,\n",
       " 'Historical': 9925,\n",
       " 'Log Cabin/Rustic': 2726,\n",
       " 'Mansion': 641,\n",
       " 'Modern': 577,\n",
       " 'Other': 207280,\n",
       " 'Prefab, Modular': 5294,\n",
       " 'Raised Ranch': 36173,\n",
       " 'Ranch\\\\Rambler': 183357,\n",
       " 'Traditional': 10793,\n",
       " 'Tudor': 1323,\n",
       " 'Unfinished\\\\Under Construction': 4562,\n",
       " 'Victorian': 2094,\n",
       " 'nan': 667275}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encode style attribute\n",
    "#dict(train['style'].value_counts())\n",
    "\n",
    "train['style'] = train['style'].astype(str)\n",
    "before_transform_dict = dict(train['style'].value_counts())\n",
    "before_transform_dict\n",
    "\n",
    "make_one_hot_encoding(train, 9, 'roof_type')\n",
    "make_one_hot_encoding(train, 25, 'roof_cover')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fips_cd                       False\n",
      "apn                           False\n",
      "IsTraining                    False\n",
      "prop_house_number              True\n",
      "prop_house_number_2            True\n",
      "prop_house_number_suffix       True\n",
      "prop_direction_left            True\n",
      "prop_street_name               True\n",
      "prop_suffix                    True\n",
      "prop_direction_right           True\n",
      "prop_unit_type                 True\n",
      "prop_unit_number               True\n",
      "prop_city                      True\n",
      "prop_state                    False\n",
      "prop_zip_code                  True\n",
      "prop_zip_plus_4                True\n",
      "dwelling_type                  True\n",
      "zoning                         True\n",
      "census_tract                   True\n",
      "mobile_home_ind                True\n",
      "timeshare_ind                  True\n",
      "acres                         False\n",
      "land_square_footage           False\n",
      "irregular_lot_flg              True\n",
      "assessed_total_value          False\n",
      "assessed_land_value           False\n",
      "assessed_improvement_value    False\n",
      "market_total_value            False\n",
      "market_land_value             False\n",
      "market_improvement_value      False\n",
      "                              ...  \n",
      "total_rooms                   False\n",
      "total_baths_calculated        False\n",
      "air_conditioning               True\n",
      "basement_cd                    True\n",
      "condition                      True\n",
      "construction_type              True\n",
      "fireplace_num                 False\n",
      "garage_type                    True\n",
      "heating_type                   True\n",
      "construction_quality           True\n",
      "roof_cover                     True\n",
      "roof_type                      True\n",
      "stories_cd                     True\n",
      "style                          True\n",
      "geocode_latitude               True\n",
      "geocode_longitude              True\n",
      "avm_final_value0               True\n",
      "avm_std_deviation0             True\n",
      "avm_final_value1               True\n",
      "avm_std_deviation1             True\n",
      "avm_final_value2               True\n",
      "avm_std_deviation2             True\n",
      "avm_final_value3               True\n",
      "avm_std_deviation3             True\n",
      "avm_final_value4               True\n",
      "avm_std_deviation4             True\n",
      "first_mtg_amt                  True\n",
      "distressed_sale_flg            True\n",
      "sale_amt                      False\n",
      "transaction_date              False\n",
      "Length: 73, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# which columns contain NaN's\n",
    "print(train.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_integer_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m     \"\"\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-5b4a109d4358>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/datathon_propattributes.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'IsTraining'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# COLUMNS TO DROP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdropped_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'irregular_lot_flg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'prop_house_number_suffix'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'apn'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1034\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# COLUMNS TO DROP\n",
    "dropped_cols = ['irregular_lot_flg','prop_house_number_suffix','apn']\n",
    "train.drop(dropped_cols, axis = 1, inplace = True)\n",
    "properties = train.columns\n",
    "\n",
    "float_columns = properties[train.dtypes == 'float64']\n",
    "int_columns = properties[train.dtypes == 'int64']\n",
    "\n",
    "numeric_train = train[float_columns.extend(int_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean Data\n",
    "set(numeric_train['prop_house_number_suffix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model Training\n",
    "\n",
    "# Parameters\n",
    "XGB_WEIGHT = 0.6000\n",
    "BASELINE_WEIGHT = 0.0000\n",
    "OLS_WEIGHT = 0.0600\n",
    "\n",
    "XGB1_WEIGHT = 0.8000  # Weight of first in combination of two XGB models\n",
    "\n",
    "BASELINE_PRED = 0.0115   # Baseline based on mean of training data, per Oleg\n",
    "\n",
    "\n",
    "\n",
    "##  XGBoost   ##\n",
    "\n",
    "\n",
    "\n",
    "##### PROCESS DATA FOR XGBOOST\n",
    "\n",
    "print( \"\\nProcessing data for XGBoost ...\")\n",
    "for c in properties.columns:\n",
    "    properties[c]=properties[c].fillna(-1)\n",
    "    if properties[c].dtype == 'object':\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(properties[c].values))\n",
    "        properties[c] = lbl.transform(list(properties[c].values))\n",
    "\n",
    "train_df = train.merge(properties, how='left', on='parcelid')\n",
    "x_train = train_df.drop(['parcelid', 'logerror','transactiondate'], axis=1)\n",
    "x_test = properties.drop(['parcelid'], axis=1)\n",
    "# shape        \n",
    "\n",
    "# drop out ouliers\n",
    "train_df=train_df[ train_df.logerror > -0.4 ]\n",
    "train_df=train_df[ train_df.logerror < 0.419 ]\n",
    "x_train=train_df.drop(['parcelid', 'logerror','transactiondate'], axis=1)\n",
    "y_train = train_df[\"logerror\"].values.astype(np.float32)\n",
    "y_mean = np.mean(y_train)\n",
    "\n",
    "##### RUN XGBOOST\n",
    "\n",
    "print(\"\\nSetting up data for XGBoost ...\")\n",
    "# xgboost params\n",
    "xgb_params = {\n",
    "    'eta': 0.037,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.80,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'mae',\n",
    "    'lambda': 0.8,   \n",
    "    'alpha': 0.4, \n",
    "    'base_score': y_mean,\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dtest = xgb.DMatrix(x_test)\n",
    "\n",
    "num_boost_rounds = 250\n",
    "\n",
    "# train model\n",
    "model = xgb.train(dict(xgb_params, silent=1), dtrain, num_boost_round=num_boost_rounds)\n",
    "\n",
    "xgb_pred1 = model.predict(dtest)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### RUN XGBOOST AGAIN\n",
    "\n",
    "# xgboost params\n",
    "xgb_params = {\n",
    "    'eta': 0.033,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.80,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'mae',\n",
    "    'base_score': y_mean,\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "num_boost_rounds = 150\n",
    "\n",
    "model = xgb.train(dict(xgb_params, silent=1), dtrain, num_boost_round=num_boost_rounds)\n",
    "\n",
    "xgb_pred2 = model.predict(dtest)\n",
    "\n",
    "\n",
    "##### COMBINE XGBOOST RESULTS\n",
    "xgb_pred = XGB1_WEIGHT*xgb_pred1 + (1-XGB1_WEIGHT)*xgb_pred2\n",
    "\n",
    "del train_df\n",
    "del x_train\n",
    "del x_test\n",
    "del properties\n",
    "del dtest\n",
    "del dtrain\n",
    "del xgb_pred1\n",
    "del xgb_pred2 \n",
    "gc.collect()\n",
    "\n",
    "\n",
    "##    OLS     ##\n",
    "\n",
    "np.random.seed(17)\n",
    "random.seed(17)\n",
    "\n",
    "train = pd.read_csv(\"../input/train_2016_v2.csv\", parse_dates=[\"transactiondate\"])\n",
    "properties = pd.read_csv(\"../input/properties_2016.csv\")\n",
    "submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "print(len(train),len(properties),len(submission))\n",
    "\n",
    "def get_features(df):\n",
    "    df[\"transactiondate\"] = pd.to_datetime(df[\"transactiondate\"])\n",
    "    df[\"transactiondate_year\"] = df[\"transactiondate\"].dt.year\n",
    "    df[\"transactiondate_month\"] = df[\"transactiondate\"].dt.month\n",
    "    df['transactiondate'] = df['transactiondate'].dt.quarter\n",
    "    df = df.fillna(-1.0)\n",
    "    return df\n",
    "\n",
    "def MAE(y, ypred):\n",
    "    #logerror=log(Zestimate)âˆ’log(SalePrice)\n",
    "    return np.sum([abs(y[i]-ypred[i]) for i in range(len(y))]) / len(y)\n",
    "\n",
    "\n",
    "train = pd.merge(train, properties, how='left', on='parcelid')\n",
    "y = train['logerror'].values\n",
    "test = pd.merge(submission, properties, how='left', left_on='ParcelId', right_on='parcelid')\n",
    "properties = [] #memory\n",
    "\n",
    "exc = [train.columns[c] for c in range(len(train.columns)) if train.dtypes[c] == 'O'] + ['logerror','parcelid']\n",
    "col = [c for c in train.columns if c not in exc]\n",
    "\n",
    "train = get_features(train[col])\n",
    "test['transactiondate'] = '2016-01-01' #should use the most common training date\n",
    "test = get_features(test[col])\n",
    "\n",
    "reg = LinearRegression(n_jobs=-1)\n",
    "reg.fit(train, y); print('fit...')\n",
    "print(MAE(y, reg.predict(train)))\n",
    "train = [];  y = [] #memory\n",
    "\n",
    "test_dates = ['2016-10-01','2016-11-01','2016-12-01','2017-10-01','2017-11-01','2017-12-01']\n",
    "test_columns = ['201610','201611','201612','201710','201711','201712']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### COMBINE PREDICTIONS\n",
    "\n",
    "print( \"\\nCombining XGBoost, LightGBM, and baseline predicitons ...\" )\n",
    "lgb_weight = 1 - XGB_WEIGHT - BASELINE_WEIGHT - OLS_WEIGHT \n",
    "lgb_weight0 = lgb_weight / (1 - OLS_WEIGHT)\n",
    "xgb_weight0 = XGB_WEIGHT / (1 - OLS_WEIGHT)\n",
    "baseline_weight0 =  BASELINE_WEIGHT / (1 - OLS_WEIGHT)\n",
    "pred0 = xgb_weight0*xgb_pred + baseline_weight0*BASELINE_PRED + lgb_weight0*p_test\n",
    "\n",
    "print( \"\\nCombined XGB/LGB/baseline predictions:\" )\n",
    "print( pd.DataFrame(pred0).head() )\n",
    "\n",
    "print( \"\\nPredicting with OLS and combining with XGB/LGB/baseline predicitons: ...\" )\n",
    "for i in range(len(test_dates)):\n",
    "    test['transactiondate'] = test_dates[i]\n",
    "    pred = OLS_WEIGHT*reg.predict(get_features(test)) + (1-OLS_WEIGHT)*pred0\n",
    "    submission[test_columns[i]] = [float(format(x, '.4f')) for x in pred]\n",
    "    print('predict...', i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fips_cd                         int64\n",
       "apn                            object\n",
       "IsTraining                      int64\n",
       "prop_house_number              object\n",
       "prop_house_number_2            object\n",
       "prop_house_number_suffix      float64\n",
       "prop_direction_left            object\n",
       "prop_street_name               object\n",
       "prop_suffix                    object\n",
       "prop_direction_right           object\n",
       "prop_unit_type                 object\n",
       "prop_unit_number               object\n",
       "prop_city                      object\n",
       "prop_state                     object\n",
       "prop_zip_code                 float64\n",
       "prop_zip_plus_4               float64\n",
       "dwelling_type                  object\n",
       "zoning                         object\n",
       "census_tract                  float64\n",
       "mobile_home_ind                object\n",
       "timeshare_ind                  object\n",
       "acres                         float64\n",
       "land_square_footage             int64\n",
       "irregular_lot_flg             float64\n",
       "assessed_total_value          float64\n",
       "assessed_land_value           float64\n",
       "assessed_improvement_value    float64\n",
       "market_total_value            float64\n",
       "market_land_value             float64\n",
       "market_improvement_value      float64\n",
       "                               ...   \n",
       "total_rooms                     int64\n",
       "total_baths_calculated          int64\n",
       "air_conditioning               object\n",
       "basement_cd                    object\n",
       "condition                      object\n",
       "construction_type              object\n",
       "fireplace_num                   int64\n",
       "garage_type                    object\n",
       "heating_type                   object\n",
       "construction_quality           object\n",
       "roof_cover                     object\n",
       "roof_type                      object\n",
       "stories_cd                     object\n",
       "style                          object\n",
       "geocode_latitude              float64\n",
       "geocode_longitude             float64\n",
       "avm_final_value0              float64\n",
       "avm_std_deviation0            float64\n",
       "avm_final_value1              float64\n",
       "avm_std_deviation1            float64\n",
       "avm_final_value2              float64\n",
       "avm_std_deviation2            float64\n",
       "avm_final_value3              float64\n",
       "avm_std_deviation3            float64\n",
       "avm_final_value4              float64\n",
       "avm_std_deviation4            float64\n",
       "first_mtg_amt                 float64\n",
       "distressed_sale_flg            object\n",
       "sale_amt                      float64\n",
       "transaction_date               object\n",
       "Length: 73, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Inference\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Validation\n",
    "properties = train.columns\n",
    "numeric_columns = properties[train.dtypes == 'float64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fips_cd', 'IsTraining', 'land_square_footage', 'tax_year',\n",
       "       'delinquent_tax_year', 'assessed_year', 'building_square_feet',\n",
       "       'total_living_square_feet', 'total_ground_floor_square_feet',\n",
       "       'total_basement_square_feet', 'total_garage_parking_square_feet',\n",
       "       'year_built', 'effective_year_built', 'bedrooms', 'total_rooms',\n",
       "       'total_baths_calculated', 'fireplace_num'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizations\n",
    "numeric_columns = numeric_train.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: irregular_lot_flg, dtype: int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.irregular_lot_flg.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwelling_type_top_25 = ['Single Family Residential', 'Condominium (Residential)', 'Row house (Residential)', 'Residential-Vacant Land', 'Duplex (2 units, any combination)', 'Triplex (3 units, any combination)', 'Townhouse (Residential)', 'Apartments (generic)', 'Residential (General) (Single)', 'Vacant Land (General)', 'Commercial/Office/Residential Mixed Use', 'Mobile home', 'Multi-Family Dwellings (Generic, 2+)', 'Rural Residence (Agricultural)', 'Commercial (General)', 'Unusable Land (Remnant, Steep, etc.)', 'Retail Stores (Personal Services, Photography, Travel)', 'Commercial-Vacant Land', 'Exempt (full or partial)', 'Office Bldg (General)', 'Agricultural-Unimproved Vacant Land', 'Agricultural / Rural', 'Misc. Structures - Ranch, Farm, Fixtures', 'Warehouse (Industrial)', 'Commercial Building', 'Seasonal, Cabin, Vacation Residence', 'Condominium Offices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dwelling_type_top_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
