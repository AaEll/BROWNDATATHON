{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import operator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gc\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random\n",
    "import datetime as dt\n",
    "\n",
    "def find_neighbors(data, lat,long,k,n1 = 'geocode_latitude',n2 = 'geocode_longitude'):\n",
    "    tmp_arr = data[[n1,n2]]-np.array([lat,long])\n",
    "    temp_ser = np.sum(np.square(tmp_arr),axis = 1)\n",
    "    indexes = np.argsort(temp_ser)[0:k]\n",
    "    return data.loc[indexes,:]\n",
    "\n",
    "def avg_residuals(data,target = 'res'):\n",
    "    return np.sum(data['res'])\n",
    "    \n",
    "def K_NN_Residuals(data,lat,long,k = 5,target = 'res',n1 = 'geocode_latitude',n2 = 'geocode_longitude'):\n",
    "    x['KNN'] =  avg_residuals(find_neighbors(data,x[n1],x[n2],k,n1,n2),target)\n",
    "    return x\n",
    "\n",
    "    \n",
    "\n",
    "def model_fill(data,model,target):\n",
    "    truth_val = pd.isna(data[target])\n",
    "    test = data[truth_val]\n",
    "    train = data[~truth_val]\n",
    "    model.fit(train)\n",
    "    data.loc[truth_val,target] = model.predict(test)\n",
    "    return data                 \n",
    "\n",
    "def make_one_hot_encoding(data,number_of_top_values,target):\n",
    "    top_names = list(dict(data[target].value_counts()).keys())[0:number_of_top_values]\n",
    "    for name in top_names:\n",
    "        data[name] = 0\n",
    "        data.loc[data[target] == name, name] = 1\n",
    "    data.drop([target],axis = 1, inplace = True)\n",
    "    return data\n",
    "\n",
    "def change_style_attribute(x):\n",
    "    if x.isdigit():\n",
    "        return x + \".0\"\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def transform_date(data,target):\n",
    "    data.loc[:, target + '_int'] = pd.to_datetime(data[target]).dt.strftime(\"%Y%m%d\").astype(int)\n",
    "    data.drop(target,axis = 1, inplace = True)\n",
    "    return data\n",
    "\n",
    "def make_ordinal(data,target,ordered_list):\n",
    "    dict_ordered = {}\n",
    "    i = len(ordered_list)\n",
    "    \n",
    "    name_mod = target + '_ordinal'\n",
    "    data[name_mod] = 0\n",
    "    for name in ordered_list:\n",
    "        data.loc[data[target] == name, name_mod] = i\n",
    "        i -= 1\n",
    "    data.drop(target,axis = 1, inplace = True)\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaell/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (1,3,4,9,10,11,17,19,20,34,45,46,47,48,50,51,52,53,54,55,56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Import Data\n",
    "train = pd.read_csv('../data/datathon_propattributes.csv')\n",
    "train = train[train['IsTraining'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_cols = ['irregular_lot_flg','prop_house_number_suffix','apn',\n",
    "                'IsTraining',\n",
    "                'fips_cd',\n",
    "                'prop_house_number',\n",
    "                'prop_house_number_2'  ,\n",
    "                'prop_house_number_suffix' ,\n",
    "                'prop_direction_left'  ,\n",
    "                'prop_street_name'  ,     \n",
    "                'prop_suffix'  ,\n",
    "                'prop_direction_right' ,\n",
    "                'prop_unit_number' ,\n",
    "                'prop_city' ,\n",
    "                'prop_state',\n",
    "                'prop_zip_code' ,\n",
    "                'prop_zip_plus_4',\n",
    "               'census_tract',\n",
    "               'irregular_lot_flg',\n",
    "               'tax_cd_area',\n",
    "                'tax_year']\n",
    "\n",
    "one_hots = [['dwelling_type',10],\n",
    "            ['prop_unit_type',4], # maybe drop\n",
    "            ['zoning',15],\n",
    "            ['roof_type',9],\n",
    "            ['roof_cover',13],\n",
    "            ['garage_type',14],\n",
    "            ['construction_type',13],\n",
    "            ['basement_cd',7],\n",
    "            ['style',20],\n",
    "            ['stories_cd',5],\n",
    "            ['mobile_home_ind',1],\n",
    "            ['timeshare_ind',1],\n",
    "            ['distressed_sale_flg',1]]\n",
    "\n",
    "date_cols = ['transaction_date']\n",
    "\n",
    "\n",
    "condition= ['Excellent','Good','Average','Fair','Poor','Unsound']\n",
    "Construction=['A+','A','A-','B+','B','B-','C+','C','C-','D+','D','D-','E+','E','E-']\n",
    "Air_conditioning=['Central','Refrigeration','Chilled Water','Geo-Thermal','Packaged Unit','Wall','Window\\\\Unit','Evaporative Cooler','Yes','Ventilation','Partial','Other','None']\n",
    "Heating_Type= ['Central','Zone','Geo-thermal','Solar','Forced air unit','Heat Pump','Hot Water','Electric','Steam','Floor/Wall','Space/Suspended','Baseboard','Radiant','Propane','Gas','Oil','Coal','Gravity','Other','Wood Burning','Yes','Vent','None']\n",
    "\n",
    "ordinals = [['condition',condition],\n",
    "            ['construction_quality',Construction],\n",
    "            ['air_conditioning',Air_conditioning],\n",
    "            ['heating_type',Heating_Type]]\n",
    "\n",
    "\n",
    "candidates_fill = ['assessed_total_value',\n",
    "                   'assessed_land_value',\n",
    "                   'assessed_improvement_value',\n",
    "                   'market_total_value',\n",
    "                   'market_land_value',\n",
    "                   'market_improvement_value',\n",
    "                   'tax_amt',\n",
    "                    'avm_final_value0',\n",
    "                    'avm_std_deviation0',\n",
    "                    'avm_final_value1',\n",
    "                    'avm_std_deviation1',\n",
    "                    'avm_final_value2'   ,            \n",
    "                    'avm_std_deviation2',\n",
    "                    'avm_final_value3'   ,            \n",
    "                    'avm_std_deviation3',\n",
    "                    'avm_final_value4',\n",
    "                    'avm_std_deviation4' ]\n",
    "\n",
    "train.drop(dropped_cols,axis =1 , inplace = True)\n",
    "\n",
    "# Transform attributes\n",
    "train['style'] = train['style'].astype(str)\n",
    "train['style'] = train['style'].apply(change_style_attribute)\n",
    "train['stories_cd'] = train['stories_cd'].astype(str)\n",
    "\n",
    "##CONVERT STRINGS TO NUMERICAL VARIABLES##\n",
    "for target_column, number_of_top_names in one_hots:\n",
    "    make_one_hot_encoding(train,number_of_top_names,target_column)\n",
    "    \n",
    "for target_column, ordered_names in ordinals:\n",
    "    make_ordinal(train,target_column,ordered_names)\n",
    "    \n",
    "for target_column in date_cols:\n",
    "    transform_date(train,target_column)\n",
    "\n",
    "\n",
    "\n",
    "##FILL MISSING DATA IN SELECT COLUMNS##\n",
    "fill_data = train.drop(['sale_amt','geocode_longitude','geocode_latitude'],axis = 1)\n",
    "for candidate in candidates_fill:\n",
    "    model_fill(fill_data, RandomForestClassifier(), target)\n",
    "del fill_data\n",
    "\n",
    "print(train)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which columns contain NaN's\n",
    "print(train.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "\n",
    "\n",
    "\n",
    "##  XGBoost   ##\n",
    "\n",
    "x_train_first_stage = train.drop(['sale_amt','geocode_longitude','geocode_latitude'],axis = 1)\n",
    "first_stage = train[['sale_amt','geocode_longitude','geocode_latitude']]\n",
    "\n",
    "\n",
    "##### RUN XGBOOST\n",
    "\n",
    "# xgboost params\n",
    "xgb_params = {\n",
    "    'eta': 0.037,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.80,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'mae',\n",
    "    'lambda': 0.8,   \n",
    "    'alpha': 0.4, \n",
    "    'base_score': y_mean,\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "dtrain_first_stage = xgb.DMatrix(x_train_first_stage, first_stage.sale_amt)\n",
    "num_boost_rounds = 250\n",
    "# train model\n",
    "model = xgb.train(dict(xgb_params, silent=1), dtrain_first_stage, num_boost_round=num_boost_rounds)\n",
    "first_stage['pred'] = model.predict(x_train_first_stage)\n",
    "first_stage['res'] = first_stage['pred'] - first_stage['sale_amt']\n",
    "\n",
    "apply_knn = lambda x : K_NN_Residuals(first_stage,x, k = 5)\n",
    "first_stage.apply(apply_knn)\n",
    "train['KNN'] = first_stage['KNN']\n",
    "train.drop(['geocode_longitude','geocode_latitude'],axis = 1,inplace = True)\n",
    "del first_stage\n",
    "del dtrain_first_stage\n",
    "del model\n",
    "del x_train_first_stage\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop(['sale_amt'],axis = 1)\n",
    "y_train = train.sale_amt\n",
    "\n",
    "#Create Location Param#\n",
    "##### RUN XGBOOST AGAIN\n",
    "\n",
    "# xgboost params\n",
    "xgb_params = {\n",
    "    'eta': 0.033,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.80,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'mae',\n",
    "    'base_score': y_mean,\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "\n",
    "num_boost_rounds = 150\n",
    "\n",
    "model = xgb.train(dict(xgb_params, silent=1), dtrain, num_boost_round=num_boost_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_pred2 = model.predict(dtest)\n",
    "\n",
    "\n",
    "##### COMBINE XGBOOST RESULTS\n",
    "xgb_pred = XGB1_WEIGHT*xgb_pred1 + (1-XGB1_WEIGHT)*xgb_pred2\n",
    "\n",
    "del train_df\n",
    "del x_train\n",
    "del x_test\n",
    "del properties\n",
    "del dtest\n",
    "del dtrain\n",
    "del xgb_pred1\n",
    "del xgb_pred2 \n",
    "gc.collect()\n",
    "\n",
    "\n",
    "##    OLS     ##\n",
    "\n",
    "np.random.seed(17)\n",
    "random.seed(17)\n",
    "\n",
    "train = pd.read_csv(\"../input/train_2016_v2.csv\", parse_dates=[\"transactiondate\"])\n",
    "properties = pd.read_csv(\"../input/properties_2016.csv\")\n",
    "submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "print(len(train),len(properties),len(submission))\n",
    "\n",
    "def get_features(df):\n",
    "    df[\"transactiondate\"] = pd.to_datetime(df[\"transactiondate\"])\n",
    "    df[\"transactiondate_year\"] = df[\"transactiondate\"].dt.year\n",
    "    df[\"transactiondate_month\"] = df[\"transactiondate\"].dt.month\n",
    "    df['transactiondate'] = df['transactiondate'].dt.quarter\n",
    "    df = df.fillna(-1.0)\n",
    "    return df\n",
    "\n",
    "def MAE(y, ypred):\n",
    "    #logerror=log(Zestimate)−log(SalePrice)\n",
    "    return np.sum([abs(y[i]-ypred[i]) for i in range(len(y))]) / len(y)\n",
    "\n",
    "\n",
    "train = pd.merge(train, properties, how='left', on='parcelid')\n",
    "y = train['logerror'].values\n",
    "test = pd.merge(submission, properties, how='left', left_on='ParcelId', right_on='parcelid')\n",
    "properties = [] #memory\n",
    "\n",
    "exc = [train.columns[c] for c in range(len(train.columns)) if train.dtypes[c] == 'O'] + ['logerror','parcelid']\n",
    "col = [c for c in train.columns if c not in exc]\n",
    "\n",
    "train = get_features(train[col])\n",
    "test['transactiondate'] = '2016-01-01' #should use the most common training date\n",
    "test = get_features(test[col])\n",
    "\n",
    "reg = LinearRegression(n_jobs=-1)\n",
    "reg.fit(train, y); print('fit...')\n",
    "print(MAE(y, reg.predict(train)))\n",
    "train = [];  y = [] #memory\n",
    "\n",
    "test_dates = ['2016-10-01','2016-11-01','2016-12-01','2017-10-01','2017-11-01','2017-12-01']\n",
    "test_columns = ['201610','201611','201612','201710','201711','201712']\n",
    "\n",
    "# Parameters\n",
    "XGB_WEIGHT = 0.6000\n",
    "BASELINE_WEIGHT = 0.0000\n",
    "OLS_WEIGHT = 0.0600\n",
    "XGB1_WEIGHT = 0.8000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### COMBINE PREDICTIONS\n",
    "\n",
    "print( \"\\nCombining XGBoost, LightGBM, and baseline predicitons ...\" )\n",
    "lgb_weight = 1 - XGB_WEIGHT - BASELINE_WEIGHT - OLS_WEIGHT \n",
    "lgb_weight0 = lgb_weight / (1 - OLS_WEIGHT)\n",
    "xgb_weight0 = XGB_WEIGHT / (1 - OLS_WEIGHT)\n",
    "baseline_weight0 =  BASELINE_WEIGHT / (1 - OLS_WEIGHT)\n",
    "pred0 = xgb_weight0*xgb_pred + baseline_weight0*BASELINE_PRED + lgb_weight0*p_test\n",
    "\n",
    "print( \"\\nCombined XGB/LGB/baseline predictions:\" )\n",
    "print( pd.DataFrame(pred0).head() )\n",
    "\n",
    "print( \"\\nPredicting with OLS and combining with XGB/LGB/baseline predicitons: ...\" )\n",
    "for i in range(len(test_dates)):\n",
    "    test['transactiondate'] = test_dates[i]\n",
    "    pred = OLS_WEIGHT*reg.predict(get_features(test)) + (1-OLS_WEIGHT)*pred0\n",
    "    submission[test_columns[i]] = [float(format(x, '.4f')) for x in pred]\n",
    "    print('predict...', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fips_cd                         int64\n",
       "apn                            object\n",
       "IsTraining                      int64\n",
       "prop_house_number              object\n",
       "prop_house_number_2            object\n",
       "prop_house_number_suffix      float64\n",
       "prop_direction_left            object\n",
       "prop_street_name               object\n",
       "prop_suffix                    object\n",
       "prop_direction_right           object\n",
       "prop_unit_type                 object\n",
       "prop_unit_number               object\n",
       "prop_city                      object\n",
       "prop_state                     object\n",
       "prop_zip_code                 float64\n",
       "prop_zip_plus_4               float64\n",
       "dwelling_type                  object\n",
       "zoning                         object\n",
       "census_tract                  float64\n",
       "mobile_home_ind                object\n",
       "timeshare_ind                  object\n",
       "acres                         float64\n",
       "land_square_footage             int64\n",
       "irregular_lot_flg             float64\n",
       "assessed_total_value          float64\n",
       "assessed_land_value           float64\n",
       "assessed_improvement_value    float64\n",
       "market_total_value            float64\n",
       "market_land_value             float64\n",
       "market_improvement_value      float64\n",
       "                               ...   \n",
       "total_rooms                     int64\n",
       "total_baths_calculated          int64\n",
       "air_conditioning               object\n",
       "basement_cd                    object\n",
       "condition                      object\n",
       "construction_type              object\n",
       "fireplace_num                   int64\n",
       "garage_type                    object\n",
       "heating_type                   object\n",
       "construction_quality           object\n",
       "roof_cover                     object\n",
       "roof_type                      object\n",
       "stories_cd                     object\n",
       "style                          object\n",
       "geocode_latitude              float64\n",
       "geocode_longitude             float64\n",
       "avm_final_value0              float64\n",
       "avm_std_deviation0            float64\n",
       "avm_final_value1              float64\n",
       "avm_std_deviation1            float64\n",
       "avm_final_value2              float64\n",
       "avm_std_deviation2            float64\n",
       "avm_final_value3              float64\n",
       "avm_std_deviation3            float64\n",
       "avm_final_value4              float64\n",
       "avm_std_deviation4            float64\n",
       "first_mtg_amt                 float64\n",
       "distressed_sale_flg            object\n",
       "sale_amt                      float64\n",
       "transaction_date               object\n",
       "Length: 73, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Inference\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Validation\n",
    "properties = train.columns\n",
    "numeric_columns = properties[train.dtypes == 'float64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fips_cd', 'IsTraining', 'land_square_footage', 'tax_year',\n",
       "       'delinquent_tax_year', 'assessed_year', 'building_square_feet',\n",
       "       'total_living_square_feet', 'total_ground_floor_square_feet',\n",
       "       'total_basement_square_feet', 'total_garage_parking_square_feet',\n",
       "       'year_built', 'effective_year_built', 'bedrooms', 'total_rooms',\n",
       "       'total_baths_calculated', 'fireplace_num'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizations\n",
    "numeric_columns = numeric_train.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y    1962567\n",
       "Name: distressed_sale_flg, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.distressed_sale_flg.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwelling_type_top_25 = ['Single Family Residential', 'Condominium (Residential)', 'Row house (Residential)', 'Residential-Vacant Land', 'Duplex (2 units, any combination)', 'Triplex (3 units, any combination)', 'Townhouse (Residential)', 'Apartments (generic)', 'Residential (General) (Single)', 'Vacant Land (General)', 'Commercial/Office/Residential Mixed Use', 'Mobile home', 'Multi-Family Dwellings (Generic, 2+)', 'Rural Residence (Agricultural)', 'Commercial (General)', 'Unusable Land (Remnant, Steep, etc.)', 'Retail Stores (Personal Services, Photography, Travel)', 'Commercial-Vacant Land', 'Exempt (full or partial)', 'Office Bldg (General)', 'Agricultural-Unimproved Vacant Land', 'Agricultural / Rural', 'Misc. Structures - Ranch, Farm, Fixtures', 'Warehouse (Industrial)', 'Commercial Building', 'Seasonal, Cabin, Vacation Residence', 'Condominium Offices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['timeshare_ind', 'acres', 'land_square_footage', 'assessed_total_value', 'assessed_land_value', 'assessed_improvement_value', 'market_total_value', 'market_land_value', 'market_improvement_value', 'tax_amt', 'delinquent_tax_year', 'assessed_year', 'building_square_feet', 'total_living_square_feet', 'total_ground_floor_square_feet', 'total_basement_square_feet', 'total_garage_parking_square_feet', 'year_built', 'effective_year_built', 'bedrooms', 'total_rooms', 'total_baths_calculated', 'air_conditioning', 'condition', 'fireplace_num', 'heating_type', 'construction_quality', 'geocode_latitude', 'geocode_longitude', 'avm_final_value0', 'avm_std_deviation0', 'avm_final_value1', 'avm_std_deviation1', 'avm_final_value2', 'avm_std_deviation2', 'avm_final_value3', 'avm_std_deviation3', 'avm_final_value4', 'avm_std_deviation4', 'first_mtg_amt', 'distressed_sale_flg', 'sale_amt', 'transaction_date', 'Single Family Residential', 'Condominium (Residential)', 'Row house (Residential)', 'Residential-Vacant Land', 'Duplex (2 units, any combination)', 'Triplex (3 units, any combination)', 'Townhouse (Residential)', 'Apartments (generic)', 'Residential (General) (Single)', 'Vacant Land (General)', '#', 'APT', 'UNIT', 'STE', 'R2', 'RSA5', 'R1', 'R3', 'RM1', 'RS', 'RA', 'RSA3', 'RB', 'R4', 'RC', 'R', 'RR', 'A', 'B', 'GABLE', 'HIP', 'FLAT', 'GAMBREL', 'MANSARD', 'SHED', 'GABLE OR HIP', 'DOME', 'SAWTOOTH', 'Asphalt', 'Shingle (Not Wood)', 'Slate', 'Tar & Gravel', 'Composition Shingle', 'Other', 'Roll Composition', 'Metal', 'Wood Shake/ Shingles', 'Asbestos', 'Built-up', 'Tile', 'Wood', 'Garage', 'Attached Garage', 'Underground/Basement', 'Detached Garage', 'None', 'Mixed', 'Carport', 'Open', 'Yes - Unspecified', 'Built-in', 'Parking Lot', 'Parking Structure', 'Covered', 'Paved/Surfaced', 'Frame', 'Masonry', 'Brick', 'Concrete', 'Stone', 'Steel', 'Concrete Block', 'Log', 'Manufactured', 'Full Basement', 'Unfinished Basement', 'Unspecified Basement', 'Partial Basement', 'No Basement', 'Improved Basement (Finished)', 'Daylight, Partial', 'nan', 'Colonial', 'Ranch\\\\Rambler', '29.0', '38.0', 'Conventional', 'Cape Cod', '31.0', '35.0', 'Raised Ranch', '41.0', 'Contemporary', 'Bungalow', '40.0', '33.0', '36.0', 'Traditional', 'Historical', '34.0', '200.0', '100.0', '300.0', '150.0']\n"
     ]
    }
   ],
   "source": [
    "print(list(train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
