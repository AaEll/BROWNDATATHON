{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gc\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import random\n",
    "import datetime as dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "train = pd.read_csv('../data/datathon_propattributes.csv')\n",
    "train = train[train['IsTraining'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_cols = ['irregular_lot_flg','prop_house_number_suffix','apn',\n",
    "                'prop_house_number',\n",
    "                'prop_house_number_2'  ,\n",
    "                'prop_house_number_suffix' ,\n",
    "                'prop_direction_left'  ,\n",
    "                'prop_street_name'  ,     \n",
    "                'prop_suffix'  ,\n",
    "                'prop_direction_right' ,\n",
    "                'prop_unit_type',\n",
    "                'prop_unit_number' ,\n",
    "                'prop_city' ,\n",
    "                'prop_state',\n",
    "                'prop_zip_code' ,\n",
    "                'prop_zip_plus_4',\n",
    "                'zoning',\n",
    "               'census_tract',\n",
    "                'mobile_home_ind']\n",
    "\n",
    "dwelling_type_top_25 = ['Single Family Residential', 'Condominium (Residential)', 'Row house (Residential)', 'Residential-Vacant Land', 'Duplex (2 units, any combination)', 'Triplex (3 units, any combination)', 'Townhouse (Residential)', 'Apartments (generic)', 'Residential (General) (Single)', 'Vacant Land (General)', 'Commercial/Office/Residential Mixed Use', 'Mobile home', 'Multi-Family Dwellings (Generic, 2+)', 'Rural Residence (Agricultural)', 'Commercial (General)', 'Unusable Land (Remnant, Steep, etc.)', 'Retail Stores (Personal Services, Photography, Travel)', 'Commercial-Vacant Land', 'Exempt (full or partial)', 'Office Bldg (General)', 'Agricultural-Unimproved Vacant Land', 'Agricultural / Rural', 'Misc. Structures - Ranch, Farm, Fixtures', 'Warehouse (Industrial)', 'Commercial Building', 'Seasonal, Cabin, Vacation Residence', 'Condominium Offices']\n",
    "for dwell_type in dwelling_type_top_25:\n",
    "    train[dwell_type] = 0\n",
    "    train.loc[train.dwelling_type == dwell_type, dwell_type] = 1\n",
    "\n",
    "#train.drop(['dwelling_type'],axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fips_cd                       False\n",
      "apn                           False\n",
      "IsTraining                    False\n",
      "prop_house_number              True\n",
      "prop_house_number_2            True\n",
      "prop_house_number_suffix       True\n",
      "prop_direction_left            True\n",
      "prop_street_name               True\n",
      "prop_suffix                    True\n",
      "prop_direction_right           True\n",
      "prop_unit_type                 True\n",
      "prop_unit_number               True\n",
      "prop_city                      True\n",
      "prop_state                    False\n",
      "prop_zip_code                  True\n",
      "prop_zip_plus_4                True\n",
      "dwelling_type                  True\n",
      "zoning                         True\n",
      "census_tract                   True\n",
      "mobile_home_ind                True\n",
      "timeshare_ind                  True\n",
      "acres                         False\n",
      "land_square_footage           False\n",
      "irregular_lot_flg              True\n",
      "assessed_total_value          False\n",
      "assessed_land_value           False\n",
      "assessed_improvement_value    False\n",
      "market_total_value            False\n",
      "market_land_value             False\n",
      "market_improvement_value      False\n",
      "                              ...  \n",
      "total_rooms                   False\n",
      "total_baths_calculated        False\n",
      "air_conditioning               True\n",
      "basement_cd                    True\n",
      "condition                      True\n",
      "construction_type              True\n",
      "fireplace_num                 False\n",
      "garage_type                    True\n",
      "heating_type                   True\n",
      "construction_quality           True\n",
      "roof_cover                     True\n",
      "roof_type                      True\n",
      "stories_cd                     True\n",
      "style                          True\n",
      "geocode_latitude               True\n",
      "geocode_longitude              True\n",
      "avm_final_value0               True\n",
      "avm_std_deviation0             True\n",
      "avm_final_value1               True\n",
      "avm_std_deviation1             True\n",
      "avm_final_value2               True\n",
      "avm_std_deviation2             True\n",
      "avm_final_value3               True\n",
      "avm_std_deviation3             True\n",
      "avm_final_value4               True\n",
      "avm_std_deviation4             True\n",
      "first_mtg_amt                  True\n",
      "distressed_sale_flg            True\n",
      "sale_amt                      False\n",
      "transaction_date              False\n",
      "Length: 73, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# which columns contain NaN's\n",
    "print(train.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_integer_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m     \"\"\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-5b4a109d4358>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/datathon_propattributes.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'IsTraining'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# COLUMNS TO DROP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdropped_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'irregular_lot_flg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'prop_house_number_suffix'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'apn'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1034\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# COLUMNS TO DROP\n",
    "dropped_cols = ['irregular_lot_flg','prop_house_number_suffix','apn']\n",
    "train.drop(dropped_cols, axis = 1, inplace = True)\n",
    "properties = train.columns\n",
    "\n",
    "float_columns = properties[train.dtypes == 'float64']\n",
    "int_columns = properties[train.dtypes == 'int64']\n",
    "\n",
    "numeric_train = train[float_columns.extend(int_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Data\n",
    "set(numeric_train['prop_house_number_suffix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "\n",
    "# Parameters\n",
    "XGB_WEIGHT = 0.6000\n",
    "BASELINE_WEIGHT = 0.0000\n",
    "OLS_WEIGHT = 0.0600\n",
    "\n",
    "XGB1_WEIGHT = 0.8000  # Weight of first in combination of two XGB models\n",
    "\n",
    "BASELINE_PRED = 0.0115   # Baseline based on mean of training data, per Oleg\n",
    "\n",
    "\n",
    "\n",
    "##  XGBoost   ##\n",
    "\n",
    "\n",
    "\n",
    "##### PROCESS DATA FOR XGBOOST\n",
    "\n",
    "print( \"\\nProcessing data for XGBoost ...\")\n",
    "for c in properties.columns:\n",
    "    properties[c]=properties[c].fillna(-1)\n",
    "    if properties[c].dtype == 'object':\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(properties[c].values))\n",
    "        properties[c] = lbl.transform(list(properties[c].values))\n",
    "\n",
    "train_df = train.merge(properties, how='left', on='parcelid')\n",
    "x_train = train_df.drop(['parcelid', 'logerror','transactiondate'], axis=1)\n",
    "x_test = properties.drop(['parcelid'], axis=1)\n",
    "# shape        \n",
    "\n",
    "# drop out ouliers\n",
    "train_df=train_df[ train_df.logerror > -0.4 ]\n",
    "train_df=train_df[ train_df.logerror < 0.419 ]\n",
    "x_train=train_df.drop(['parcelid', 'logerror','transactiondate'], axis=1)\n",
    "y_train = train_df[\"logerror\"].values.astype(np.float32)\n",
    "y_mean = np.mean(y_train)\n",
    "\n",
    "##### RUN XGBOOST\n",
    "\n",
    "print(\"\\nSetting up data for XGBoost ...\")\n",
    "# xgboost params\n",
    "xgb_params = {\n",
    "    'eta': 0.037,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.80,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'mae',\n",
    "    'lambda': 0.8,   \n",
    "    'alpha': 0.4, \n",
    "    'base_score': y_mean,\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dtest = xgb.DMatrix(x_test)\n",
    "\n",
    "num_boost_rounds = 250\n",
    "\n",
    "# train model\n",
    "model = xgb.train(dict(xgb_params, silent=1), dtrain, num_boost_round=num_boost_rounds)\n",
    "\n",
    "xgb_pred1 = model.predict(dtest)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### RUN XGBOOST AGAIN\n",
    "\n",
    "# xgboost params\n",
    "xgb_params = {\n",
    "    'eta': 0.033,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.80,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'mae',\n",
    "    'base_score': y_mean,\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "num_boost_rounds = 150\n",
    "\n",
    "model = xgb.train(dict(xgb_params, silent=1), dtrain, num_boost_round=num_boost_rounds)\n",
    "\n",
    "xgb_pred2 = model.predict(dtest)\n",
    "\n",
    "\n",
    "##### COMBINE XGBOOST RESULTS\n",
    "xgb_pred = XGB1_WEIGHT*xgb_pred1 + (1-XGB1_WEIGHT)*xgb_pred2\n",
    "\n",
    "del train_df\n",
    "del x_train\n",
    "del x_test\n",
    "del properties\n",
    "del dtest\n",
    "del dtrain\n",
    "del xgb_pred1\n",
    "del xgb_pred2 \n",
    "gc.collect()\n",
    "\n",
    "\n",
    "##    OLS     ##\n",
    "\n",
    "np.random.seed(17)\n",
    "random.seed(17)\n",
    "\n",
    "train = pd.read_csv(\"../input/train_2016_v2.csv\", parse_dates=[\"transactiondate\"])\n",
    "properties = pd.read_csv(\"../input/properties_2016.csv\")\n",
    "submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "print(len(train),len(properties),len(submission))\n",
    "\n",
    "def get_features(df):\n",
    "    df[\"transactiondate\"] = pd.to_datetime(df[\"transactiondate\"])\n",
    "    df[\"transactiondate_year\"] = df[\"transactiondate\"].dt.year\n",
    "    df[\"transactiondate_month\"] = df[\"transactiondate\"].dt.month\n",
    "    df['transactiondate'] = df['transactiondate'].dt.quarter\n",
    "    df = df.fillna(-1.0)\n",
    "    return df\n",
    "\n",
    "def MAE(y, ypred):\n",
    "    #logerror=log(Zestimate)−log(SalePrice)\n",
    "    return np.sum([abs(y[i]-ypred[i]) for i in range(len(y))]) / len(y)\n",
    "\n",
    "\n",
    "train = pd.merge(train, properties, how='left', on='parcelid')\n",
    "y = train['logerror'].values\n",
    "test = pd.merge(submission, properties, how='left', left_on='ParcelId', right_on='parcelid')\n",
    "properties = [] #memory\n",
    "\n",
    "exc = [train.columns[c] for c in range(len(train.columns)) if train.dtypes[c] == 'O'] + ['logerror','parcelid']\n",
    "col = [c for c in train.columns if c not in exc]\n",
    "\n",
    "train = get_features(train[col])\n",
    "test['transactiondate'] = '2016-01-01' #should use the most common training date\n",
    "test = get_features(test[col])\n",
    "\n",
    "reg = LinearRegression(n_jobs=-1)\n",
    "reg.fit(train, y); print('fit...')\n",
    "print(MAE(y, reg.predict(train)))\n",
    "train = [];  y = [] #memory\n",
    "\n",
    "test_dates = ['2016-10-01','2016-11-01','2016-12-01','2017-10-01','2017-11-01','2017-12-01']\n",
    "test_columns = ['201610','201611','201612','201710','201711','201712']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### COMBINE PREDICTIONS\n",
    "\n",
    "print( \"\\nCombining XGBoost, LightGBM, and baseline predicitons ...\" )\n",
    "lgb_weight = 1 - XGB_WEIGHT - BASELINE_WEIGHT - OLS_WEIGHT \n",
    "lgb_weight0 = lgb_weight / (1 - OLS_WEIGHT)\n",
    "xgb_weight0 = XGB_WEIGHT / (1 - OLS_WEIGHT)\n",
    "baseline_weight0 =  BASELINE_WEIGHT / (1 - OLS_WEIGHT)\n",
    "pred0 = xgb_weight0*xgb_pred + baseline_weight0*BASELINE_PRED + lgb_weight0*p_test\n",
    "\n",
    "print( \"\\nCombined XGB/LGB/baseline predictions:\" )\n",
    "print( pd.DataFrame(pred0).head() )\n",
    "\n",
    "print( \"\\nPredicting with OLS and combining with XGB/LGB/baseline predicitons: ...\" )\n",
    "for i in range(len(test_dates)):\n",
    "    test['transactiondate'] = test_dates[i]\n",
    "    pred = OLS_WEIGHT*reg.predict(get_features(test)) + (1-OLS_WEIGHT)*pred0\n",
    "    submission[test_columns[i]] = [float(format(x, '.4f')) for x in pred]\n",
    "    print('predict...', i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fips_cd                         int64\n",
       "apn                            object\n",
       "IsTraining                      int64\n",
       "prop_house_number              object\n",
       "prop_house_number_2            object\n",
       "prop_house_number_suffix      float64\n",
       "prop_direction_left            object\n",
       "prop_street_name               object\n",
       "prop_suffix                    object\n",
       "prop_direction_right           object\n",
       "prop_unit_type                 object\n",
       "prop_unit_number               object\n",
       "prop_city                      object\n",
       "prop_state                     object\n",
       "prop_zip_code                 float64\n",
       "prop_zip_plus_4               float64\n",
       "dwelling_type                  object\n",
       "zoning                         object\n",
       "census_tract                  float64\n",
       "mobile_home_ind                object\n",
       "timeshare_ind                  object\n",
       "acres                         float64\n",
       "land_square_footage             int64\n",
       "irregular_lot_flg             float64\n",
       "assessed_total_value          float64\n",
       "assessed_land_value           float64\n",
       "assessed_improvement_value    float64\n",
       "market_total_value            float64\n",
       "market_land_value             float64\n",
       "market_improvement_value      float64\n",
       "                               ...   \n",
       "total_rooms                     int64\n",
       "total_baths_calculated          int64\n",
       "air_conditioning               object\n",
       "basement_cd                    object\n",
       "condition                      object\n",
       "construction_type              object\n",
       "fireplace_num                   int64\n",
       "garage_type                    object\n",
       "heating_type                   object\n",
       "construction_quality           object\n",
       "roof_cover                     object\n",
       "roof_type                      object\n",
       "stories_cd                     object\n",
       "style                          object\n",
       "geocode_latitude              float64\n",
       "geocode_longitude             float64\n",
       "avm_final_value0              float64\n",
       "avm_std_deviation0            float64\n",
       "avm_final_value1              float64\n",
       "avm_std_deviation1            float64\n",
       "avm_final_value2              float64\n",
       "avm_std_deviation2            float64\n",
       "avm_final_value3              float64\n",
       "avm_std_deviation3            float64\n",
       "avm_final_value4              float64\n",
       "avm_std_deviation4            float64\n",
       "first_mtg_amt                 float64\n",
       "distressed_sale_flg            object\n",
       "sale_amt                      float64\n",
       "transaction_date               object\n",
       "Length: 73, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Inference\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "properties = train.columns\n",
    "numeric_columns = properties[train.dtypes == 'float64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fips_cd', 'IsTraining', 'land_square_footage', 'tax_year',\n",
       "       'delinquent_tax_year', 'assessed_year', 'building_square_feet',\n",
       "       'total_living_square_feet', 'total_ground_floor_square_feet',\n",
       "       'total_basement_square_feet', 'total_garage_parking_square_feet',\n",
       "       'year_built', 'effective_year_built', 'bedrooms', 'total_rooms',\n",
       "       'total_baths_calculated', 'fireplace_num'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizations\n",
    "numeric_columns = numeric_train.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Single Family Residential', 'Condominium (Residential)', 'Row house (Residential)', 'Residential-Vacant Land', 'Duplex (2 units, any combination)', 'Triplex (3 units, any combination)', 'Townhouse (Residential)', 'Apartments (generic)', 'Residential (General) (Single)', 'Vacant Land (General)', 'Commercial/Office/Residential Mixed Use', 'Mobile home', 'Multi-Family Dwellings (Generic, 2+)', 'Rural Residence (Agricultural)', 'Commercial (General)', 'Unusable Land (Remnant, Steep, etc.)', 'Retail Stores (Personal Services, Photography, Travel)', 'Commercial-Vacant Land', 'Exempt (full or partial)', 'Office Bldg (General)', 'Agricultural-Unimproved Vacant Land', 'Agricultural / Rural', 'Misc. Structures - Ranch, Farm, Fixtures', 'Warehouse (Industrial)', 'Commercial Building', 'Seasonal, Cabin, Vacation Residence', 'Condominium Offices', 'Miscellaneous (General)', 'Restaurant', 'Auto repair, auto parts, Garage', 'Misc Residential Improvement', 'Residential Common Area (Condo/PUD/etc.)', 'Apartment house (5+ units)', 'Governmental/Public Use (General)', 'Commercial Condominium (not offices)', 'Industrial (General)', 'Manufacturing (light)', 'Parking Lot', 'Religious, Church, Worship', 'Vacant parcels with improvements', 'Industrial-Vacant Land', 'Recreational/Entertainment (General)', 'Quadruplex (4 units, any combination)', 'Charitable organization', 'Farm land', 'Campground, RV Park', 'Residential Income (General) (Multi-Family)', '1901', 'Mini-Warehouse, Storage', 'Store/Office (mixed use)', 'Manufactured,Modular,Pre-Fabricated Homes', 'Rural Improved / Non-Residential', 'Under Construction', 'Crop, Field Crops, Row Crops (all soil classes)', 'Condominiums (Industrial)', 'Financial Bldg', 'Timberland, Forest, Trees (Agricultural)', 'Service station (full service)', 'Medical Bldg', 'Planned Unit Development (PUD Residential)', 'Vehicle Rentals, Vehicle Sales', 'Retired, Handicap, Convalescent, Nursing Home', 'Public School', 'Parking Garage, Parking Structure', 'State Owned', 'Garden Apt, Court Apt (5+ units)', 'Cluster home (Residential)', 'Department Store (apparel, household goods, furniture)', 'Private Preserve, Open Space-Vacant Land (Forest Land, Conservation)', 'Office Bldg (multi-story)', 'Timeshare (Residential)', 'Hotel', 'Regional Shopping Center or Mall with Anchor store', 'Bar, Tavern', 'Light Industrial', 'Boarding or Rooming House,Apt Hotel,Transient Lodgings', 'County Owned', 'City, Municipal, Town, Village Owned', 'Day care, Pre-school (Commercial)', 'Neighborhood Shopping Center, Strip Center/Mall, Enterprise Zone', 'Convenience store', 'Drive-thru Restaurant, Fast Food', 'Motel', 'Grocery, Supermarket', 'Forest (park; reserve; recreation, conservation)', 'Gas Station', 'Mobile Home or Trailer Park', 'Commercial Office (General)', 'Stores & Apartments', 'Professional Bldg (legal; insurance; real estate; etc.)', 'Regulating Districts & Assessments; Tax Abatement', 'Parochial School, Private School', 'Hotel or Motel', 'Distribution Warehouse (Regional)', 'Store (multi-story)', 'Government-Vacant Land', 'Car wash', 'Laboratory, Research and Development Facility, Cosmetics, Pharmaceutical', 'Mixed Use (Commercial/Industrial)', 'Service Shop', 'Clubs, Lodges, Professional Associations', 'Service station w/convenience store (food mart)', 'Other exempt property', 'Public Utility', 'Wholesale Outlet, Franchise Discount Store', 'Construction/Contracting Services (Industrial)', 'Institutional (General)', 'Funeral Home, Mortuary (Commercial)', 'Livestock', 'Welfare, Social Service, Low Income Housing (Exempt)', 'Truck Terminal (Motor Freight)', 'Community Shopping Plaza or Shopping Center, Mini-Mall', 'Gym, Health Spa', 'Common Area (Industrial)', 'Quarries', 'Hotel-Resort', 'Storage yard, Open Storage (light equipment, material)', 'Factory (medium)', 'Common Area (commercial)', 'Poultry Farm', 'Boat slips, Marina, Yacht Club, Boat Landing', 'Lumberyard, Building Materials', 'Dry Cleaner, Laundry', 'Horticulture, Growing Houses (Agricultural)', 'Post Office', 'Hospital-PRIVATE', 'Federal Property', 'Emergency (Police; Fire; etc)', 'Park, Playground, Picnic Area', 'Private Utility', 'Sub-Surface Rights (mineral)', 'Govt. Administrative Office', 'Recreation Center', 'Foundry, Industrial Plant', 'Highrise Apartments', 'Heavy Manufacturing', 'Bungalow (Residential)', 'Golf Course', 'Cemetery (Exempt)', 'Institutional-Vacant Land', 'Theater', 'Telegraph, Telephone Communications', 'Apartment house (100+ units)', 'Bowling Alley', 'Gasoline, Fuel Bulk Storage', 'Dormitory, Group Quarters (Residential)', 'Industrial Park', 'Medical Clinic', 'Nursery, Greenhouse, Florist', 'Redevlopment Agency or Zone', 'Amusement Park, Tourist Attraction', 'Heavy Industrial (General)', 'Veterinary or Animal Hospital', 'Crematorium, Mortuary (Exempt)', 'Water Area (Lakes; River; Shore)', 'Educational Colleges, University-PUBLIC', 'Roads, Streets, Bridges', 'Mining', 'Storage yard (junk; auto wrecking, salvage)', 'Processing Plant', 'Hospital-PUBLIC', 'Radio or TV Station Communications', 'Educational - PRIVATE', 'Museums, Library, Art Gallery', 'SBE - Special Assessments', 'Take-out Restaurant', 'Orchard (fruit; nut)', 'Rail (Right-of-way & track)', 'Airport & related', 'Country Club', 'Dental Bldg', 'Fraternity or Sorority House', 'Printing & Publishing (Light Industrial)', 'Lumber & Wood Product MFG (including furniture)', 'Outdoor Recreation: Beach, Mountain, Desert', 'Mill', 'Industrial Loft Building, Loft Building', 'Transportation & Communications (General)', 'Dairy Farm', 'Common Area (misc.)', 'Recreational Non-Taxable (Camps, Boy Scouts)', 'Cold Storage', 'Nightclub (Cocktail Lounge)', 'Pasture, Meadow', 'Laundromat (self-service)', 'Food Packing, Packing Plant', 'Waste Land, Marsh, Swamp', 'Chemical', 'Truck stop (fuel and diner)', 'Special Purpose', 'Riding Stable, Trails', 'Surface Rights (Grazing, timber, coal,)', 'Distillery, Brewery, Bottling', 'Range land (grazing)', 'Waste Disposal, Sewage, Treatment facility', 'Grain Elevator', 'Community Center', 'Skating rink, Ice Skating, Roller Skating', 'Residential Condominium Development (Association Assessment)', 'Convenience Store with fuel', 'Utilities (Right-of-way ONLY)', '1902', 'Professional Bldg (multi-story)', 'Racquet or Tennis Court', 'Railroad & related', 'Food Processing', 'Bus Terminal', 'Refinery, Petroleum Products', 'Cultural, Historical', 'Go-carts, Miniature Golf, Water slides', 'Microwave', 'Fish Camps, Game Club, Target Shooting', 'Shopping Center COMMON AREA parking, park etc.', 'Cable TV Station Communications', 'Military', 'Public Health Care Facility', 'Multi-Tenant Industrial Bldg', 'Bed & Breakfast', 'Farm Supply & Equipment (Commercial)', 'Marine Facility/Boat Repairs (small craft or sailboat)', 'Drug Store or Pharmacy', 'Garden Center, Home Improvement DIY', 'Leasehold Rights (misc.)', 'Public Swimming Pool', 'Transportation', 'Golf Driving Range', 'Auditoriums', 'Kennel', 'Dump Site', 'Slaughter House, Stockyard', 'Commercial Auto Transportation/Storage', '0532', 'Liquor Store', 'Printer - Retail', 'Assembly (light industrial)', 'Race track', 'Recreational-Vacant Land', 'Right-of-Way (not rail, road or utility)', 'Reservoir, Water Supply', 'Pipeline or Right-of-Way', 'Piers, Wharf', 'Cooperative (Residential)', 'Skyscraper/Highrise (Commercial Offices)', 'Bakery', 'Arenas, Convention Center', 'Correctional Facility, Jails, Prisons, Insane Asylum', 'Paper Product MFG & related products', 'Abandoned Site, Contaminated Site', 'Drive-In Theater'])\n"
     ]
    }
   ],
   "source": [
    "print(dict(train.dwelling_type.value_counts()).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    4\n",
      "Name: col1, dtype: int64\n",
      "   col1  col2\n",
      "1     2     2\n",
      "0     1     3\n",
      "2     3     5\n"
     ]
    }
   ],
   "source": [
    "def find_neighbors(train, lat,long,k,n1 = 'geocode_latitude',n2 = 'geocode_longitude'):\n",
    "    tmp_arr = train[[n1,n2]]-np.array([lat,long])\n",
    "    temp_ser = np.sum(np.square(tmp_arr),axis = 1)\n",
    "    indexes = np.argsort(temp_ser)[0:k]\n",
    "    return train.loc[indexes,:]\n",
    "\n",
    "def avg_residuals(train,model, target = 'sale_amt'):\n",
    "    return np.sum(model.predict(train.drop('sale_amt')) - train['sale_amt'])\n",
    "    \n",
    "def K_NN_Residuals(model,train,lat,long,k = 5,target = 'sale_amt',n1 = 'geocode_latitude',n2 = 'geocode_longitude'):\n",
    "    return avg_residuals(find_neighbors(train,lat,long,k,n1,n2),model,target)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5\n",
       "1    0\n",
       "2    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.Series([1,2,3,4,5,.1])\n",
    "k=3\n",
    "np.argsort(x)[:k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
