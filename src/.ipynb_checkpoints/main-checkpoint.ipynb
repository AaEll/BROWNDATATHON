{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import operator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gc\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import random\n",
    "import datetime as dt\n",
    "\n",
    "def K_NN_Residuals(data, x,k = 5,n1 = 'geocode_latitude',n2 = 'geocode_longitude',target = 'res'):\n",
    "    tmp_arr = data[[n1,n2]]-np.array([x[n1],x[n2]])\n",
    "    tmp_arr = np.square(tmp_arr).sum(axis = 1)\n",
    "    ranks = tmp_arr.rank()\n",
    "    return np.sum(data[ranks<=k])[0]\n",
    "\n",
    "\n",
    "def model_fill(data,model,target):\n",
    "    \n",
    "    truth_val = pd.isna(data[target])\n",
    "    test = data[truth_val]\n",
    "    train = data[~truth_val]\n",
    "    if test.shape[0] == 0 or train.shape[0] == 0:\n",
    "        return data\n",
    "    train = train.fillna(0)\n",
    "    test  = test.fillna(0)\n",
    "    model.fit(train.drop(target,axis = 1),train[target])\n",
    "    data.loc[truth_val,target] = model.predict(test.drop(target,axis = 1))\n",
    "    \n",
    "    return data\n",
    "\n",
    "def make_one_hot_encoding(data,number_of_top_values,target):\n",
    "    top_names = list(dict(data[target].value_counts()).keys())[0:number_of_top_values]\n",
    "    for name in top_names:\n",
    "        data[name] = 0\n",
    "        data.loc[data[target] == name, name] = 1\n",
    "    data.drop([target],axis = 1, inplace = True)\n",
    "    return data\n",
    "\n",
    "def change_style_attribute(x):\n",
    "    if x.isdigit():\n",
    "        return x + \".0\"\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def transform_date(data,target):\n",
    "    data.loc[:, target + '_int'] = pd.to_datetime(data[target]).dt.strftime(\"%Y%m%d\").astype(int)\n",
    "    data.drop(target,axis = 1, inplace = True)\n",
    "    return data\n",
    "\n",
    "def make_ordinal(data,target,ordered_list):\n",
    "    dict_ordered = {}\n",
    "    i = len(ordered_list)\n",
    "    \n",
    "    name_mod = target + '_ordinal'\n",
    "    data[name_mod] = 0\n",
    "    for name in ordered_list:\n",
    "        data.loc[data[target] == name, name_mod] = i\n",
    "        i -= 1\n",
    "    data.drop(target,axis = 1, inplace = True)\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaell/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (1,3,4,9,10,11,17,19,20,34,45,46,47,48,50,51,52,53,54,55,56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bdd08712907d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/datathon_propattributes.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1034\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import Data\n",
    "train = pd.read_csv('../data/datathon_propattributes.csv').sample(frac = 1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_cols = ['irregular_lot_flg','prop_house_number_suffix','apn',\n",
    "                'IsTraining',\n",
    "                'fips_cd',\n",
    "                'prop_house_number',\n",
    "                'prop_house_number_2'  ,\n",
    "                'prop_house_number_suffix' ,\n",
    "                'prop_direction_left'  ,\n",
    "                'prop_street_name'  ,     \n",
    "                'prop_suffix'  ,\n",
    "                'prop_direction_right' ,\n",
    "                'prop_unit_number' ,\n",
    "                'prop_city' ,\n",
    "                'prop_state',\n",
    "                'prop_zip_code' ,\n",
    "                'prop_zip_plus_4',\n",
    "               'census_tract',\n",
    "               'irregular_lot_flg',\n",
    "               'tax_cd_area',\n",
    "                'tax_year']\n",
    "\n",
    "one_hots = [['dwelling_type',10],\n",
    "            ['prop_unit_type',4], # maybe drop\n",
    "            ['zoning',15],\n",
    "            ['roof_type',9],\n",
    "            ['roof_cover',13],\n",
    "            ['garage_type',14],\n",
    "            ['construction_type',13],\n",
    "            ['basement_cd',7],\n",
    "            ['style',20],\n",
    "            ['stories_cd',5],\n",
    "            ['mobile_home_ind',1],\n",
    "            ['timeshare_ind',1],\n",
    "            ['distressed_sale_flg',1]]\n",
    "\n",
    "date_cols = ['transaction_date']\n",
    "\n",
    "\n",
    "condition= ['Excellent','Good','Average','Fair','Poor','Unsound']\n",
    "Construction=['A+','A','A-','B+','B','B-','C+','C','C-','D+','D','D-','E+','E','E-']\n",
    "Air_conditioning=['Central','Refrigeration','Chilled Water','Geo-Thermal','Packaged Unit','Wall','Window\\\\Unit','Evaporative Cooler','Yes','Ventilation','Partial','Other','None']\n",
    "Heating_Type= ['Central','Zone','Geo-thermal','Solar','Forced air unit','Heat Pump','Hot Water','Electric','Steam','Floor/Wall','Space/Suspended','Baseboard','Radiant','Propane','Gas','Oil','Coal','Gravity','Other','Wood Burning','Yes','Vent','None']\n",
    "\n",
    "ordinals = [['condition',condition],\n",
    "            ['construction_quality',Construction],\n",
    "            ['air_conditioning',Air_conditioning],\n",
    "            ['heating_type',Heating_Type]]\n",
    "\n",
    "\n",
    "candidates_fill = ['assessed_total_value',\n",
    "                   'assessed_land_value',\n",
    "                   'assessed_improvement_value',\n",
    "                   'market_total_value',\n",
    "                   'market_land_value',\n",
    "                   'market_improvement_value',\n",
    "                   'tax_amt',\n",
    "                    'avm_final_value0',\n",
    "                    'avm_std_deviation0',\n",
    "                    'avm_final_value1',\n",
    "                    'avm_std_deviation1',\n",
    "                    'avm_final_value2'   ,            \n",
    "                    'avm_std_deviation2',\n",
    "                    'avm_final_value3'   ,            \n",
    "                    'avm_std_deviation3',\n",
    "                    'avm_final_value4',\n",
    "                    'avm_std_deviation4' ]\n",
    "\n",
    "# Transform attributes\n",
    "train['style'] = train['style'].astype(str)\n",
    "train['style'] = train['style'].apply(change_style_attribute)\n",
    "train['stories_cd'] = train['stories_cd'].astype(str)\n",
    "\n",
    "##CONVERT STRINGS TO NUMERICAL VARIABLES##\n",
    "for target_column, number_of_top_names in one_hots:\n",
    "    make_one_hot_encoding(train,number_of_top_names,target_column)\n",
    "    \n",
    "for target_column, ordered_names in ordinals:\n",
    "    make_ordinal(train,target_column,ordered_names)\n",
    "    \n",
    "for target_column in date_cols:\n",
    "    transform_date(train,target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.apply(pd.to_numeric)\n",
    "\n",
    "##FILL MISSING DATA IN SELECT COLUMNS##\n",
    "fill_data = train.drop(dropped_cols.extend(['sale_amt','geocode_longitude','geocode_latitude']),axis = 1)\n",
    "for candidate in candidates_fill:\n",
    "    model_fill(fill_data, RandomForestRegressor(), candidate)\n",
    "    \n",
    "test = train[train['IsTraining'] != 1]\n",
    "train = train[train['IsTraining'] == 1]\n",
    "train.drop(dropped_cols,axis =1 , inplace = True)\n",
    "del fill_data\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which columns contain NaN's\n",
    "train.fillna(method='bfill',inplace = True)\n",
    "print(train.isna().any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaell/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/aaell/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaell/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-27f3eeabb4c0>\", line 35, in <module>\n",
      "    train['KNN'] = first_stage.apply(apply_knn,axis = 1)\n",
      "  File \"/Users/aaell/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\", line 6014, in apply\n",
      "    return op.get_result()\n",
      "  File \"/Users/aaell/anaconda3/lib/python3.7/site-packages/pandas/core/apply.py\", line 142, in get_result\n",
      "    return self.apply_standard()\n",
      "  File \"/Users/aaell/anaconda3/lib/python3.7/site-packages/pandas/core/apply.py\", line 242, in apply_standard\n",
      "    labels=labels)\n",
      "  File \"pandas/_libs/reduction.pyx\", line 637, in pandas._libs.reduction.reduce\n",
      "  File \"pandas/_libs/reduction.pyx\", line 149, in pandas._libs.reduction.Reducer.get_result\n",
      "  File \"<ipython-input-6-27f3eeabb4c0>\", line 34, in <lambda>\n",
      "    apply_knn = lambda x : K_NN_Residuals(first_stage,x, k = 5)\n",
      "  File \"<ipython-input-1-6e46f5a03de2>\", line 15, in K_NN_Residuals\n",
      "    ranks = tmp_arr.rank()\n",
      "  File \"/Users/aaell/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\", line 7288, in rank\n",
      "    return ranker(self)\n",
      "  File \"/Users/aaell/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\", line 7280, in ranker\n",
      "    pct=pct)\n",
      "  File \"/Users/aaell/anaconda3/lib/python3.7/site-packages/pandas/core/algorithms.py\", line 872, in rank\n",
      "    na_option=na_option, pct=pct)\n",
      "  File \"pandas/_libs/algos_rank_helper.pxi\", line 303, in pandas._libs.algos.rank_1d_float64\n",
      "  File \"/Users/aaell/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py\", line 1079, in diff\n",
      "    def diff(a, n=1, axis=-1):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaell/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2018, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaell/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/aaell/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/aaell/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/aaell/anaconda3/lib/python3.7/inspect.py\", line 1500, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/aaell/anaconda3/lib/python3.7/inspect.py\", line 1458, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/aaell/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/aaell/anaconda3/lib/python3.7/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/Users/aaell/anaconda3/lib/python3.7/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/Users/aaell/anaconda3/lib/python3.7/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/Users/aaell/anaconda3/lib/python3.7/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "\n",
    "\n",
    "\n",
    "##  XGBoost   ##\n",
    "\n",
    "x_train_first_stage = train.drop(['sale_amt','geocode_longitude','geocode_latitude'],axis = 1)\n",
    "first_stage = train[['sale_amt','geocode_longitude','geocode_latitude']]\n",
    "\n",
    "\n",
    "##### RUN XGBOOST\n",
    "\n",
    "# xgboost params\n",
    "xgb_params = {\n",
    "    'eta': 0.037,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.80,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'mae',\n",
    "    'lambda': 0.8,   \n",
    "    'alpha': 0.4, \n",
    "    'base_score': np.mean(first_stage.sale_amt),\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "dtrain_first_stage = xgb.DMatrix(x_train_first_stage, first_stage.sale_amt)\n",
    "num_boost_rounds = 250\n",
    "# train model\n",
    "model = xgb.train(dict(xgb_params, silent=1), dtrain_first_stage, num_boost_round=num_boost_rounds)\n",
    "\n",
    "first_stage['pred'] = model.predict(dtrain_first_stage)\n",
    "first_stage['res'] = first_stage['pred'] - first_stage['sale_amt']\n",
    "\n",
    "demo_sample = first_stage.sample(frac = 1e-3)\n",
    "apply_knn = lambda x : K_NN_Residuals(demo_sample,x, k = 5)\n",
    "train['KNN'] = first_stage.apply(apply_knn,axis = 1)\n",
    "test['KNN'] = test.apply(apply_knn,axis = 1)\n",
    "\n",
    "test.drop(['geocode_longitude','geocode_latitude'],axis = 1,inplace = True)\n",
    "train.drop(['geocode_longitude','geocode_latitude'],axis = 1,inplace = True)\n",
    "del first_stage\n",
    "del dtrain_first_stage\n",
    "del model\n",
    "del x_train_first_stage\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop(['sale_amt'],axis = 1)\n",
    "y_train = train.sale_amt\n",
    "\n",
    "x_test = test.drop(['sale_amt'],axis = 1)\n",
    "y_test = test.sale_amt\n",
    "#Create Location Param#\n",
    "##### RUN XGBOOST AGAIN\n",
    "\n",
    "# xgboost params\n",
    "xgb_params = {\n",
    "    'eta': 0.033,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.80,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'mae',\n",
    "    'base_score': np.mean(y_train),\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dtest = xgb.DMatrix(x_test, y_test)\n",
    "\n",
    "num_boost_rounds = 150\n",
    "\n",
    "model = xgb.train(dict(xgb_params, silent=1), dtrain, num_boost_round=num_boost_rounds)\n",
    "xgb_pred = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(y, ypred):\n",
    "    #logerror=log(Zestimate)−log(SalePrice)\n",
    "    return np.sum([abs(y[i]-ypred[i]) for i in range(len(y))]) / len(y)\n",
    "\n",
    "print(MAE(y_test, xgb_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##### COMBINE XGBOOST RESULTS\n",
    "xgb_pred = XGB1_WEIGHT*xgb_pred1 + (1-XGB1_WEIGHT)*xgb_pred2\n",
    "\n",
    "del train_df\n",
    "del x_train\n",
    "del x_test\n",
    "del properties\n",
    "del dtest\n",
    "del dtrain\n",
    "del xgb_pred1\n",
    "del xgb_pred2 \n",
    "gc.collect()\n",
    "\n",
    "\n",
    "##    OLS     ##\n",
    "\n",
    "np.random.seed(17)\n",
    "random.seed(17)\n",
    "\n",
    "train = pd.read_csv(\"../input/train_2016_v2.csv\", parse_dates=[\"transactiondate\"])\n",
    "properties = pd.read_csv(\"../input/properties_2016.csv\")\n",
    "submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "print(len(train),len(properties),len(submission))\n",
    "\n",
    "def get_features(df):\n",
    "    df[\"transactiondate\"] = pd.to_datetime(df[\"transactiondate\"])\n",
    "    df[\"transactiondate_year\"] = df[\"transactiondate\"].dt.year\n",
    "    df[\"transactiondate_month\"] = df[\"transactiondate\"].dt.month\n",
    "    df['transactiondate'] = df['transactiondate'].dt.quarter\n",
    "    df = df.fillna(-1.0)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "train = pd.merge(train, properties, how='left', on='parcelid')\n",
    "y = train['logerror'].values\n",
    "test = pd.merge(submission, properties, how='left', left_on='ParcelId', right_on='parcelid')\n",
    "properties = [] #memory\n",
    "\n",
    "exc = [train.columns[c] for c in range(len(train.columns)) if train.dtypes[c] == 'O'] + ['logerror','parcelid']\n",
    "col = [c for c in train.columns if c not in exc]\n",
    "\n",
    "train = get_features(train[col])\n",
    "test['transactiondate'] = '2016-01-01' #should use the most common training date\n",
    "test = get_features(test[col])\n",
    "\n",
    "reg = LinearRegression(n_jobs=-1)\n",
    "reg.fit(train, y); print('fit...')\n",
    "print(MAE(y, reg.predict(train)))\n",
    "train = [];  y = [] #memory\n",
    "\n",
    "test_dates = ['2016-10-01','2016-11-01','2016-12-01','2017-10-01','2017-11-01','2017-12-01']\n",
    "test_columns = ['201610','201611','201612','201710','201711','201712']\n",
    "\n",
    "# Parameters\n",
    "XGB_WEIGHT = 0.6000\n",
    "BASELINE_WEIGHT = 0.0000\n",
    "OLS_WEIGHT = 0.0600\n",
    "XGB1_WEIGHT = 0.8000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### COMBINE PREDICTIONS\n",
    "\n",
    "print( \"\\nCombining XGBoost, LightGBM, and baseline predicitons ...\" )\n",
    "lgb_weight = 1 - XGB_WEIGHT - BASELINE_WEIGHT - OLS_WEIGHT \n",
    "lgb_weight0 = lgb_weight / (1 - OLS_WEIGHT)\n",
    "xgb_weight0 = XGB_WEIGHT / (1 - OLS_WEIGHT)\n",
    "baseline_weight0 =  BASELINE_WEIGHT / (1 - OLS_WEIGHT)\n",
    "pred0 = xgb_weight0*xgb_pred + baseline_weight0*BASELINE_PRED + lgb_weight0*p_test\n",
    "\n",
    "print( \"\\nCombined XGB/LGB/baseline predictions:\" )\n",
    "print( pd.DataFrame(pred0).head() )\n",
    "\n",
    "print( \"\\nPredicting with OLS and combining with XGB/LGB/baseline predicitons: ...\" )\n",
    "for i in range(len(test_dates)):\n",
    "    test['transactiondate'] = test_dates[i]\n",
    "    pred = OLS_WEIGHT*reg.predict(get_features(test)) + (1-OLS_WEIGHT)*pred0\n",
    "    submission[test_columns[i]] = [float(format(x, '.4f')) for x in pred]\n",
    "    print('predict...', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fips_cd                         int64\n",
       "apn                            object\n",
       "IsTraining                      int64\n",
       "prop_house_number              object\n",
       "prop_house_number_2            object\n",
       "prop_house_number_suffix      float64\n",
       "prop_direction_left            object\n",
       "prop_street_name               object\n",
       "prop_suffix                    object\n",
       "prop_direction_right           object\n",
       "prop_unit_type                 object\n",
       "prop_unit_number               object\n",
       "prop_city                      object\n",
       "prop_state                     object\n",
       "prop_zip_code                 float64\n",
       "prop_zip_plus_4               float64\n",
       "dwelling_type                  object\n",
       "zoning                         object\n",
       "census_tract                  float64\n",
       "mobile_home_ind                object\n",
       "timeshare_ind                  object\n",
       "acres                         float64\n",
       "land_square_footage             int64\n",
       "irregular_lot_flg             float64\n",
       "assessed_total_value          float64\n",
       "assessed_land_value           float64\n",
       "assessed_improvement_value    float64\n",
       "market_total_value            float64\n",
       "market_land_value             float64\n",
       "market_improvement_value      float64\n",
       "                               ...   \n",
       "total_rooms                     int64\n",
       "total_baths_calculated          int64\n",
       "air_conditioning               object\n",
       "basement_cd                    object\n",
       "condition                      object\n",
       "construction_type              object\n",
       "fireplace_num                   int64\n",
       "garage_type                    object\n",
       "heating_type                   object\n",
       "construction_quality           object\n",
       "roof_cover                     object\n",
       "roof_type                      object\n",
       "stories_cd                     object\n",
       "style                          object\n",
       "geocode_latitude              float64\n",
       "geocode_longitude             float64\n",
       "avm_final_value0              float64\n",
       "avm_std_deviation0            float64\n",
       "avm_final_value1              float64\n",
       "avm_std_deviation1            float64\n",
       "avm_final_value2              float64\n",
       "avm_std_deviation2            float64\n",
       "avm_final_value3              float64\n",
       "avm_std_deviation3            float64\n",
       "avm_final_value4              float64\n",
       "avm_std_deviation4            float64\n",
       "first_mtg_amt                 float64\n",
       "distressed_sale_flg            object\n",
       "sale_amt                      float64\n",
       "transaction_date               object\n",
       "Length: 73, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Inference\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Validation\n",
    "properties = train.columns\n",
    "numeric_columns = properties[train.dtypes == 'float64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fips_cd', 'IsTraining', 'land_square_footage', 'tax_year',\n",
       "       'delinquent_tax_year', 'assessed_year', 'building_square_feet',\n",
       "       'total_living_square_feet', 'total_ground_floor_square_feet',\n",
       "       'total_basement_square_feet', 'total_garage_parking_square_feet',\n",
       "       'year_built', 'effective_year_built', 'bedrooms', 'total_rooms',\n",
       "       'total_baths_calculated', 'fireplace_num'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizations\n",
    "numeric_columns = numeric_train.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y    1962567\n",
       "Name: distressed_sale_flg, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.distressed_sale_flg.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwelling_type_top_25 = ['Single Family Residential', 'Condominium (Residential)', 'Row house (Residential)', 'Residential-Vacant Land', 'Duplex (2 units, any combination)', 'Triplex (3 units, any combination)', 'Townhouse (Residential)', 'Apartments (generic)', 'Residential (General) (Single)', 'Vacant Land (General)', 'Commercial/Office/Residential Mixed Use', 'Mobile home', 'Multi-Family Dwellings (Generic, 2+)', 'Rural Residence (Agricultural)', 'Commercial (General)', 'Unusable Land (Remnant, Steep, etc.)', 'Retail Stores (Personal Services, Photography, Travel)', 'Commercial-Vacant Land', 'Exempt (full or partial)', 'Office Bldg (General)', 'Agricultural-Unimproved Vacant Land', 'Agricultural / Rural', 'Misc. Structures - Ranch, Farm, Fixtures', 'Warehouse (Industrial)', 'Commercial Building', 'Seasonal, Cabin, Vacation Residence', 'Condominium Offices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3703055    2005660.0\n",
       "1993572    1112910.0\n",
       "1406605    1112910.0\n",
       "3317860    2005660.0\n",
       "3629787    2246660.0\n",
       "899394      876900.0\n",
       "1457060    1367967.0\n",
       "2245357    1367967.0\n",
       "3225126    1367967.0\n",
       "2415985    1112910.0\n",
       "2178668    2225010.0\n",
       "3232299    1367967.0\n",
       "1330244    2005660.0\n",
       "3407980    2005660.0\n",
       "3984122    1741660.0\n",
       "2277522    2225010.0\n",
       "24694       945015.0\n",
       "1628689     876900.0\n",
       "578614     2225010.0\n",
       "223583      945015.0\n",
       "3030833    2300010.0\n",
       "2242983    2225010.0\n",
       "Name: KNN, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['KNN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
